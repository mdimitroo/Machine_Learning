# ML Concepts & Techniques

This directory contains fundamental machine learning concepts, techniques, and methodologies that are essential for understanding and implementing ML models effectively.

## Categories

### 1. Data Preprocessing
Techniques for preparing and cleaning data before training models.

- [Normalization & Standardization](preprocessing/normalization/)
- [Handling Missing Values](preprocessing/missing_values/)
- [Categorical Encoding](preprocessing/categorical_encoding/)
- [Feature Scaling](preprocessing/feature_scaling/)
- [Outlier Detection & Treatment](preprocessing/outliers/)

### 2. Regularization
Techniques to prevent overfitting and improve generalization.

- [L1 Regularization (Lasso)](regularization/l1_regularization/)
- [L2 Regularization (Ridge)](regularization/l2_regularization/)
- [Elastic Net](regularization/elastic_net/)
- [Dropout](regularization/dropout/)
- [Early Stopping](regularization/early_stopping/)

### 3. Model Evaluation
Methods and metrics for assessing model performance.

- [Cross-Validation](evaluation/cross_validation/)
- [Train/Validation/Test Split](evaluation/train_test_split/)
- [Classification Metrics](evaluation/classification_metrics/)
- [Regression Metrics](evaluation/regression_metrics/)
- [Confusion Matrix](evaluation/confusion_matrix/)
- [ROC Curve & AUC](evaluation/roc_auc/)
- [Bias-Variance Tradeoff](evaluation/bias_variance/)

### 4. Optimization
Algorithms and techniques for optimizing model parameters.

- [Gradient Descent](optimization/gradient_descent/)
- [Stochastic Gradient Descent (SGD)](optimization/stochastic_gradient_descent/)
- [Learning Rate](optimization/learning_rate/)
- [Momentum](optimization/momentum/)
- [Adam Optimizer](optimization/adam/)

### 5. Feature Engineering & Selection
Techniques for creating and selecting the best features.

- [Feature Selection](feature_engineering/feature_selection/)
- [Feature Extraction](feature_engineering/feature_extraction/)
- [Polynomial Features](feature_engineering/polynomial_features/)
- [Feature Importance](feature_engineering/feature_importance/)

### 6. Hyperparameter Tuning
Methods for finding optimal hyperparameters.

- [Grid Search](hyperparameter_tuning/grid_search/)
- [Random Search](hyperparameter_tuning/random_search/)
- [Bayesian Optimization](hyperparameter_tuning/bayesian_optimization/)

### 7. Ensemble Methods
Techniques for combining multiple models.

- [Bagging](ensemble_methods/bagging/)
- [Boosting](ensemble_methods/boosting/)
- [Stacking](ensemble_methods/stacking/)
- [Voting Classifiers](ensemble_methods/voting/)

### 8. Loss Functions
Different loss functions for various problem types.

- [Mean Squared Error (MSE)](loss_functions/mse/)
- [Mean Absolute Error (MAE)](loss_functions/mae/)
- [Cross-Entropy Loss](loss_functions/cross_entropy/)
- [Hinge Loss](loss_functions/hinge_loss/)
- [Huber Loss](loss_functions/huber_loss/)

### 9. Overfitting & Underfitting
Understanding and addressing model complexity issues.

- [Overfitting](overfitting_underfitting/overfitting/)
- [Underfitting](overfitting_underfitting/underfitting/)
- [Model Complexity](overfitting_underfitting/model_complexity/)

### 10. Data Imbalance
Handling imbalanced datasets.

- [SMOTE](data_imbalance/smote/)
- [Class Weighting](data_imbalance/class_weighting/)
- [Resampling Techniques](data_imbalance/resampling/)
